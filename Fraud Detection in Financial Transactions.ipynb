{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl3jpRhYK890"
      },
      "source": [
        "**Business Need for Fraud Detection in Financial Transactions**\n",
        "\n",
        "Problem Statement\n",
        "\n",
        "Financial institutions, e-commerce platforms, and online payment systems face significant losses due to fraudulent transactions. Fraudsters use stolen credit card details, fake identities, and other malicious tactics to perform unauthorized transactions.\n",
        "\n",
        "Why is Fraud Detection Important?\n",
        "\n",
        "Financial Loss Prevention: Banks and businesses lose billions annually due to fraud.\n",
        "\n",
        "Customer Trust & Retention: Ensuring transaction security enhances customer confidence.\n",
        "\n",
        "Regulatory Compliance: Companies must comply with financial regulations to prevent fraud.\n",
        "\n",
        "Operational Efficiency: Detecting fraud early saves investigation costs and reduces chargebacks.\n",
        "\n",
        "Business Impact\n",
        "\n",
        "Reduced Chargebacks & Losses üè¶\n",
        "\n",
        "Early fraud detection minimizes financial losses.\n",
        "\n",
        "Enhanced Security & Compliance üîê\n",
        "\n",
        "Detecting anomalies ensures compliance with anti-fraud regulations.\n",
        "\n",
        "Improved Customer Experience üí≥\n",
        "\n",
        "Preventing fraud protects customer accounts and builds trust.\n",
        "\n",
        "Objective of the Project\n",
        "\n",
        "Analyze transaction data to identify patterns of fraudulent behavior.\n",
        "\n",
        "Develop a Machine Learning model to detect fraud in real-time.\n",
        "\n",
        "Improve accuracy using feature engineering and various ML algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /Users/surajitdas/Downloads/downloaded-file (6)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/path/to/directory'\n",
            "/Users/surajitdas/Downloads/downloaded-file (6)\n"
          ]
        }
      ],
      "source": [
        "cd /path/to/directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lzm8PzpyK9KB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Ul6VrTNyK9MQ",
        "outputId": "d7ed6087-3400-40cb-8649-87e92ccc6fc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in dataset: ['Time', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'Class']\n",
            "Dataset shape: (500, 13)\n",
            "\n",
            "First 5 rows:\n",
            "    Time   Amount        V1        V2        V3        V4        V5        V6  \\\n",
            "0  15795  4292.21  0.593101 -1.592994  0.126380  0.189706  0.333860 -1.535040   \n",
            "1    860  2145.54 -0.309546  0.440475  1.938929 -0.661982  1.431367 -1.880010   \n",
            "2  76820  3754.60  0.326133 -0.019638 -1.000331  0.425887  1.081767  0.712712   \n",
            "3  54886  3772.96 -1.251114  0.552490 -0.677745  0.019148 -1.312219 -1.883150   \n",
            "4   6265   516.52  0.924027  0.223914  0.513908 -0.641487  0.622070 -0.372319   \n",
            "\n",
            "         V7        V8        V9       V10  Class  \n",
            "0  0.872197 -2.386930 -0.190872 -1.846573      0  \n",
            "1 -0.315087 -0.495878 -0.198196 -0.428655      0  \n",
            "2 -0.571746  1.097300  0.510157  1.029441      0  \n",
            "3  0.332608 -1.565648  1.272570 -0.336895      0  \n",
            "4  0.933128 -3.007632  0.126314 -0.846434      0  \n",
            "\n",
            "Missing values:\n",
            "Time      0\n",
            "Amount    0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Load dataset\n",
        "data = pd.read_csv(\"fraud_detection_sample.csv\")\n",
        "df = pd.read_csv(\"fraud_detection_sample.csv\")\n",
        "print(\"Columns in dataset:\", list(df.columns))\n",
        "# Display first few rows\n",
        "print(\"Dataset shape:\", data.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())\n",
        "data.head()\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Time', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
            "       'V10', 'Class'],\n",
            "      dtype='object')\n",
            "Class\n",
            "0    480\n",
            "1     20\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    480\n",
            "1     20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n",
        "print(df['Class'].value_counts()) \n",
        "target_column = 'Class'\n",
        "print(df[target_column].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class\n",
            "0    480\n",
            "1     20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "target_column = 'Class'\n",
        "print(df[target_column].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA: Check class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "dtc50iaoLJBA",
        "outputId": "79d6c860-6dbd-471a-9d0f-a4bb2fc483ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (500, 12)\n",
            "Target shape: (500,)\n"
          ]
        }
      ],
      "source": [
        "target_column = 'Class'  # previously was 'isFraud'\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIQIPAxEK9Op",
        "outputId": "acc052f4-d686-47b3-e562-2180fad8fa91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (500, 12)\n",
            "Target shape: (500,)\n",
            "After SMOTE class distribution:\n",
            "Class\n",
            "0    480\n",
            "1    480\n",
            "Name: count, dtype: int64\n",
            "Train set size: (768, 12)\n",
            "Test set size: (192, 12)\n",
            "Feature scaling applied\n",
            "Random Forest model trained\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        96\n",
            "           1       0.92      1.00      0.96        96\n",
            "\n",
            "    accuracy                           0.96       192\n",
            "   macro avg       0.96      0.96      0.96       192\n",
            "weighted avg       0.96      0.96      0.96       192\n",
            "\n",
            "Confusion Matrix:\n",
            "[[88  8]\n",
            " [ 0 96]]\n",
            "ROC AUC Score: 0.9921\n",
            "Top 10 Important Features:\n",
            "   feature  importance\n",
            "0     Time    0.175172\n",
            "11     V10    0.168110\n",
            "1   Amount    0.116719\n",
            "3       V2    0.098973\n",
            "4       V3    0.078862\n",
            "8       V7    0.058873\n",
            "6       V5    0.057703\n",
            "9       V8    0.055534\n",
            "7       V6    0.052845\n",
            "10      V9    0.052540\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split features and target\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"After SMOTE class distribution:\")\n",
        "print(y_resampled.value_counts())\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_resampled\n",
        ")\n",
        "\n",
        "print(f\"Train set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "\n",
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Feature scaling applied\")\n",
        "\n",
        "# Model training with Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2\n",
        ")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"Random Forest model trained\")\n",
        "\n",
        "# Predictions\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Model evaluation\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "# Feature importance\n",
        "import pandas as pd\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(\"Top 10 Important Features:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JOElJfRK9Q1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KauotTAfK9UN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
